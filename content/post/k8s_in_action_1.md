---
title: "Kubernetes in action(读书 1)"
date: 2018-07-09T00:00:47+08:00
draft: false
tags: ["Kubernetes","book"]
author: "Peter Yang"
---
# 引言
几年前，很多软件程序是一个大的monolith， 这些程序一般是在一个进程里跑或者分布在几个服务器里面去跑，这些遗留系统在今天也还很多， 他们一般release的间隔很长，而且更新的不频繁，
在每个release 周期，开发人员打包好整个系统并且交给运维团队， 运维团队部署并监控他， 当有硬件错误时， 运维团队手工迁移服务到健康的机器上。
    
今天，这些大的遗留应用正拆分成更小的，独立的可运行组件（微服务），因为微服务是相互解耦的， 他们可以队里的开发，部署，更新和扩展。这就使我们能够很快很频繁的修改组件，以适应快速变化的需求。

但是随着越来越多的组件，管理这些组件就会变得很困难，我们需要能够自动一个工具自动进行将我们的应用调度到服务器上，自动的配置， 检测并且就行错误处理， 这就是k8s的用武之地

k8s可以使开发人员不用依赖于运维人员来随需部署他们的应用， 也可以帮助运维人员自动监控和当服务器挂掉时应用的自动重新部署，

k8s将你的整个datacenter抽象成一个大的计算资源， 所以，你可以直接部署和运行应用，而不用知道应用真正在哪个服务器上运行， 当你部署一个多组件的应用时， k8s会给每个组件选择一个服务器，部署并且运行它，并且是组件之间可以交互

# 为啥需要k8s

## 从一个大的app到microservice

一个大的app（Monolithic）包含多个紧耦合的多个组件，并且多个组件紧密耦合，必须要作为一个整体来开发，部署和管理，因为他们最终会作为一个进程在操作系统执行，修改任何一部分都需要从新部署整个的应用
一般都需要一个性能比较好的一些机器来跑这些应用，系统负载大时， 要么加内存，cpu（scale up） 要么加机器（scale out）

## 拆成微服务
可以将一个大的应用拆成多个微服务已提高扩展性， 微服务之间通过RESTful api(同步)或者AMQP（异步）来进行通信，因为微服务是一个单独的进程，所以他们可以单独开发和部署，改变其中一个，不需要全部部署

## 扩展微服务
微服务可以单独扩展，比较灵活

## 部署微服务
当微服务个数比较多的时候， 需要有个东西管理他们，而且微服务之间是需要通信的，必须正确配置以使多个微服务作为一个整体的应用提供服务

# 容器技术简介

k8s使用linux的容器技术来提供一个隔离的运行时环境， 所以先大概了解下容器

## 什么是容器

优点：提供隔离环境，而且比VM更加轻量级，
原理：linux Namespace可以使每个进程看到进程自己的系统（文件，进程，网络接口，主机名等）。control group(cgroup)限制每个进程可以消耗的资源（CPU，内存等）

## Docker
Docker是最广泛的容器，提供很好的隔离性，使用分层技术，可以缓存和复用层，提高效率。docker是一个 打包，分发，和运行应用的平台。打包时将应用本身和应用所处的环境（lib etc）打包到一起，打成镜像（Image），然后可以将镜像推送到Registries，就是存放镜像的一个仓库，当需要在某台机器上跑的时候， 拉下镜像，并且运行它就会产生一个容器（Container）

# Kubernetes 简介
多年之前Google内部开发系统Borg（后来叫Omega），帮助开发人员和系统管理员管理成千上万的应用和服务，2014年Google基于Borg开源了的K8s

K8s可以轻松管理容器应用，用户不必了解应用的内部细节或手工部署应用，它帮我们抽象了基础设施，不管你的集群是只有几台机器还是有几千台机器，你都可以把它们看成一个大的机器。

一个k8s集群包含多个节点，这些节点可以分成两种， 主节点（master）跑着Control Plane并且是管理整个集群， 工作节点（worker node）跑真正的应用

![][1]

Control Plane是控制整个集群的，它包含下面几个组件，API Server 是提供外部和kubernetes集群沟通的接口。资源调度（Scheduler） 会把你的应用调度到worker node上去。控制管理器（Controller-Manager）是管理整个集群的东西，比如记录worker node的状态，处理node挂掉。etcd是一个分布式的存储，保存了所有的集群配置

work node 会包含下面几个组件，容器运行时（docker，rkt）用来运行容器化的应用。 kubelet用来和API Server交互并且管理运行在node上的容器。 kube-proxy是一个应用组件之间的一个负载均衡

##在k8s集群种运行一个应用
基本上就是将一个应用的描述提交给API Server， Scheduler会将一组指定的容器分配给各个node（根据容器所需要的资源和work node种可用的资源），node接收到指令后，kubelet会去拉取指定的镜像并且运行它。

![][2]
    
k8s会不停的检查，确保集群种应用的状态是你想要的状态（desired status），如果发现有实例挂掉，它会重新启动一个新的实例
如果有node挂掉，它会将node上所有的应用在其他的node上重新启动。

在应用运行时，可以指定可以增加或减少应用的实例， k8s会帮你多起或者杀死一些实例，也可以让k8s根据当前系统的负载动态的去增加或者减少实例

因为我们的应用在集群内部的位置是不确定的（可能原来这一台node上，后来因为node挂掉重新schedule到另外一台node上），如果我们的应用是要想外部提供服务的，k8s会将会给你指定的一组提供相同服务的容器暴露一个静态的的IP地址，那个地址可以在集群内部访问，kube-proxy这个静态IP的请求会负载均衡到那一组容器中

## K8s带来的好处

简化部署， 能获取更好的硬件利用率， 健康检查和自我恢复，自动扩缩容，简化应用开发


[1]: /img/k8s-nodes.png
[2]: /img/k8s-deploy.png
